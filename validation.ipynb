{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#test_books = pd.read_csv('local_data/book_test.csv')\n",
    "test_mails = pd.read_csv('local_data/mail_test.csv')\n",
    "test_blogs = pd.read_csv('local_data/blog_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_books' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18697/1987523037.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_books\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_books' is not defined"
     ]
    }
   ],
   "source": [
    "test_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pretokenized_text</th>\n",
       "      <th>decoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mail_101</td>\n",
       "      <td>[0, 5579, 38844, 28784, 19192, 50118, 45463, 1...</td>\n",
       "      <td>&lt;s&gt;--____________________________Next\\nContent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mail_101</td>\n",
       "      <td>[175, 73, 40822, 73, 23008, 4, 47753, 116, 245...</td>\n",
       "      <td>com/links/click.cgi?5&amp;3&amp;1211134&amp;/links/2/42/5/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mail_101</td>\n",
       "      <td>[6, 50118, 463, 47, 189, 253, 62, 15, 1365, 20...</td>\n",
       "      <td>,\\nand you may end up on easy street.\\nhttp://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mail_101</td>\n",
       "      <td>[245, 73, 176, 73, 11762, 7485, 1694, 26378, 5...</td>\n",
       "      <td>5/2/calssweepsfreetext.cgi\\nQ&amp;A contest with C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mail_101</td>\n",
       "      <td>[10554, 18997, 37386, 21794, 46479, 50118, 491...</td>\n",
       "      <td>SportsLine Rewards Newsletter\"&gt;\\n&lt;/head&gt;\\n&lt;bod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67487</th>\n",
       "      <td>mail_91</td>\n",
       "      <td>[1181, 28, 1051, 4, 50118, 4148, 302, 6, 550, ...</td>\n",
       "      <td>longer be sent.\\nOn Monday, July 9, 2001 afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67488</th>\n",
       "      <td>mail_91</td>\n",
       "      <td>[111, 3506, 45, 111, 1549, 4, 1437, 1578, 5, 4...</td>\n",
       "      <td>-65 not -16.  Also the ancillary\\nis not addi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67489</th>\n",
       "      <td>mail_91</td>\n",
       "      <td>[1215, 37049, 36497, 6034, 5457, 163, 10259, 4...</td>\n",
       "      <td>_NOTIFICATION = BILL.WILLIAMS.III@ENRON.COM\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67490</th>\n",
       "      <td>mail_91</td>\n",
       "      <td>[3762, 410, 631, 15, 5, 564, 212, 4, 1437, 20,...</td>\n",
       "      <td>One little thing on the 25th.  The ancillary a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67491</th>\n",
       "      <td>mail_91</td>\n",
       "      <td>[164, 81, 5, 360, 4, 1437, 1801, 65, 50118, 27...</td>\n",
       "      <td>going over the days.  Just one\\nlittle formul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67492 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                  pretokenized_text  \\\n",
       "0      mail_101  [0, 5579, 38844, 28784, 19192, 50118, 45463, 1...   \n",
       "1      mail_101  [175, 73, 40822, 73, 23008, 4, 47753, 116, 245...   \n",
       "2      mail_101  [6, 50118, 463, 47, 189, 253, 62, 15, 1365, 20...   \n",
       "3      mail_101  [245, 73, 176, 73, 11762, 7485, 1694, 26378, 5...   \n",
       "4      mail_101  [10554, 18997, 37386, 21794, 46479, 50118, 491...   \n",
       "...         ...                                                ...   \n",
       "67487   mail_91  [1181, 28, 1051, 4, 50118, 4148, 302, 6, 550, ...   \n",
       "67488   mail_91  [111, 3506, 45, 111, 1549, 4, 1437, 1578, 5, 4...   \n",
       "67489   mail_91  [1215, 37049, 36497, 6034, 5457, 163, 10259, 4...   \n",
       "67490   mail_91  [3762, 410, 631, 15, 5, 564, 212, 4, 1437, 20,...   \n",
       "67491   mail_91  [164, 81, 5, 360, 4, 1437, 1801, 65, 50118, 27...   \n",
       "\n",
       "                                            decoded_text  \n",
       "0      <s>--____________________________Next\\nContent...  \n",
       "1      com/links/click.cgi?5&3&1211134&/links/2/42/5/...  \n",
       "2      ,\\nand you may end up on easy street.\\nhttp://...  \n",
       "3      5/2/calssweepsfreetext.cgi\\nQ&A contest with C...  \n",
       "4      SportsLine Rewards Newsletter\">\\n</head>\\n<bod...  \n",
       "...                                                  ...  \n",
       "67487   longer be sent.\\nOn Monday, July 9, 2001 afte...  \n",
       "67488   -65 not -16.  Also the ancillary\\nis not addi...  \n",
       "67489  _NOTIFICATION = BILL.WILLIAMS.III@ENRON.COM\\nS...  \n",
       "67490  One little thing on the 25th.  The ancillary a...  \n",
       "67491   going over the days.  Just one\\nlittle formul...  \n",
       "\n",
       "[67492 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pretokenized_text</th>\n",
       "      <th>decoded_text</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blog_10009</td>\n",
       "      <td>[0, 2387, 78, 3555, 4, 25980, 42, 66, 7, 192, ...</td>\n",
       "      <td>&lt;s&gt;My first entry. Testing this out to see how...</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blog_10009</td>\n",
       "      <td>[7, 1004, 314, 23, 41, 8088, 14, 56, 10, 1109,...</td>\n",
       "      <td>to turn left at an intersection that had a li...</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blog_10009</td>\n",
       "      <td>[1437, 1437, 1437, 1437, 1437, 1437, 1437, 143...</td>\n",
       "      <td>for the ungrateful.&lt;/s&gt;</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blog_10017</td>\n",
       "      <td>[0, 108, 100, 524, 10, 23611, 9376, 1437, 7774...</td>\n",
       "      <td>&lt;s&gt;'I am a banana!'  Peace out.&lt;\\s&gt;I haven't b...</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blog_10017</td>\n",
       "      <td>[35, 996, 3326, 4, 520, 132, 1187, 675, 2012, ...</td>\n",
       "      <td>:15 AM. When 2nd period starts. All day we did...</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33698</th>\n",
       "      <td>blog_9989</td>\n",
       "      <td>[79, 708, 7, 972, 42, 2173, 77, 52, 1108, 62, ...</td>\n",
       "      <td>she plans to meet this guy when we break up. ...</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33699</th>\n",
       "      <td>blog_9989</td>\n",
       "      <td>[7735, 19, 256, 10708, 8, 38, 4, 166, 202, 192...</td>\n",
       "      <td>weird with Mandy and I. We still see each oth...</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33700</th>\n",
       "      <td>blog_9989</td>\n",
       "      <td>[4, 166, 40, 192, 4, 1437, 38, 300, 127, 33734...</td>\n",
       "      <td>. We will see.  I got my aquarium stuff the ot...</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33701</th>\n",
       "      <td>blog_9989</td>\n",
       "      <td>[38, 40, 1874, 960, 8, 283, 878, 4, 404, 47, 3...</td>\n",
       "      <td>I will drop everything and come running. All ...</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33702</th>\n",
       "      <td>blog_9989</td>\n",
       "      <td>[3035, 3907, 4, 38, 300, 184, 8, 362, 103, 55,...</td>\n",
       "      <td>cool tree. I got home and took some more pict...</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33703 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                  pretokenized_text  \\\n",
       "0      blog_10009  [0, 2387, 78, 3555, 4, 25980, 42, 66, 7, 192, ...   \n",
       "1      blog_10009  [7, 1004, 314, 23, 41, 8088, 14, 56, 10, 1109,...   \n",
       "2      blog_10009  [1437, 1437, 1437, 1437, 1437, 1437, 1437, 143...   \n",
       "3      blog_10017  [0, 108, 100, 524, 10, 23611, 9376, 1437, 7774...   \n",
       "4      blog_10017  [35, 996, 3326, 4, 520, 132, 1187, 675, 2012, ...   \n",
       "...           ...                                                ...   \n",
       "33698   blog_9989  [79, 708, 7, 972, 42, 2173, 77, 52, 1108, 62, ...   \n",
       "33699   blog_9989  [7735, 19, 256, 10708, 8, 38, 4, 166, 202, 192...   \n",
       "33700   blog_9989  [4, 166, 40, 192, 4, 1437, 38, 300, 127, 33734...   \n",
       "33701   blog_9989  [38, 40, 1874, 960, 8, 283, 878, 4, 404, 47, 3...   \n",
       "33702   blog_9989  [3035, 3907, 4, 38, 300, 184, 8, 362, 103, 55,...   \n",
       "\n",
       "                                            decoded_text  age    topic  gender  \n",
       "0      <s>My first entry. Testing this out to see how...   24   indUnk    male  \n",
       "1       to turn left at an intersection that had a li...   24   indUnk    male  \n",
       "2                                for the ungrateful.</s>   24   indUnk    male  \n",
       "3      <s>'I am a banana!'  Peace out.<\\s>I haven't b...   15  Student  female  \n",
       "4      :15 AM. When 2nd period starts. All day we did...   15  Student  female  \n",
       "...                                                  ...  ...      ...     ...  \n",
       "33698   she plans to meet this guy when we break up. ...   17  Student    male  \n",
       "33699   weird with Mandy and I. We still see each oth...   17  Student    male  \n",
       "33700  . We will see.  I got my aquarium stuff the ot...   17  Student    male  \n",
       "33701   I will drop everything and come running. All ...   17  Student    male  \n",
       "33702   cool tree. I got home and took some more pict...   17  Student    male  \n",
       "\n",
       "[33703 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josephine/anaconda3/envs/sklearn-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Utilities\n",
    "#!pip install --upgrade scikit-learn\n",
    "\n",
    "from sklearn.metrics import top_k_accuracy_score, accuracy_score\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from random import shuffle\n",
    "\n",
    "TOKENIZER = AutoTokenizer.from_pretrained('roberta-large')\n",
    "\n",
    "def embed(model, texts):\n",
    "    tokenized_texts = TOKENIZER(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    embedding = model(tokenized_texts.input_ids.to(model.device),\n",
    "                      tokenized_texts.attention_mask.to(model.device),\n",
    "                      )\n",
    "    return embedding\n",
    "\n",
    "def embed_transformer(model, texts):\n",
    "    tokenized_texts = TOKENIZER(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    embedding = model(tokenized_texts.input_ids.to(model.device),\n",
    "                      attention_mask = tokenized_texts.attention_mask.to(model.device),\n",
    "                      ).pooler_output\n",
    "    return embedding\n",
    "\n",
    "def evaluate(model, data, top_k=5, N=100, repetitions=1, embed_f=embed):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs, topks = [], []\n",
    "        for _ in tqdm(range(repetitions)):           \n",
    "            authors = data.id.unique().tolist()\n",
    "            shuffle(authors)\n",
    "            random_authors = authors[:N]\n",
    "            anchors, replicas = [], []\n",
    "            for author in random_authors:\n",
    "                anchor, replica = data.loc[author == data.id].decoded_text.sample(2).tolist()\n",
    "                anchors.append(anchor)\n",
    "                replicas.append(replica)\n",
    "            \n",
    "            embedding_anchors = F.normalize(embed_f(model, anchors))\n",
    "            embedding_replicas = F.normalize(embed_f(model, replicas))\n",
    "\n",
    "            preds = embedding_anchors @ embedding_replicas.T\n",
    "            labels = torch.arange(0, len(preds)).numpy()\n",
    "\n",
    "            preds_a = F.softmax(preds, dim=-1)\n",
    "            preds_b = F.softmax(preds.T, dim=-1)\n",
    "\n",
    "            a_acc = accuracy_score(labels, preds_a.argmax(-1).cpu().numpy())\n",
    "            b_acc = accuracy_score(labels, preds_b.argmax(-1).cpu().numpy())\n",
    "            a_topk = top_k_accuracy_score(y_true=labels, y_score=preds_a.cpu().numpy(), k=top_k)\n",
    "            b_topk = top_k_accuracy_score(y_true=labels, y_score=preds_b.cpu().numpy(), k=top_k)\n",
    "\n",
    "            accs.append((a_acc+b_acc)/2)\n",
    "            topks.append((a_topk+b_topk)/2)\n",
    "\n",
    "            del embedding_anchors\n",
    "            del embedding_replicas\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        return np.mean(accs), np.mean(topks), np.std(accs), np.std(topks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zoo = {#'all': 'model/final_2022-06-21_12-22-26_lstm_books+mails+blogs.ckpt',\n",
    "            #'books': 'model/final_2022-06-28_07-55-16_lstm_books.ckpt',\n",
    "            'mails': 'model/final_2022-06-27_08-14-08_lstm_mails.ckpt',\n",
    "            'blogs': 'model/final_2022-06-15_08-10-17_lstm_blogs.ckpt',\n",
    "            }\n",
    "data_zoo = {#'all': test_books.append(test_mails).append(test_blogs),\n",
    "            #'books': test_books,\n",
    "            'mails': test_mails,\n",
    "            'blogs': test_blogs,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/josephine/proj/auth_ident/authorship-embeddings/model/final_2022-06-15_08-10-17_lstm_blogs.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k_model \u001b[38;5;129;01min\u001b[39;00m keys:\n\u001b[1;32m     15\u001b[0m     model_ckpt \u001b[38;5;241m=\u001b[39m model_zoo[k_model]\n\u001b[0;32m---> 16\u001b[0m     model \u001b[38;5;241m=\u001b[39m ContrastiveTransformer\u001b[38;5;241m.\u001b[39mload_from_checkpoint(checkpoint_path\u001b[38;5;241m=\u001b[39mmodel_ckpt)\u001b[38;5;241m.\u001b[39mcuda(DEVICE)\n\u001b[1;32m     18\u001b[0m     data_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[log] Evaluating model - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/sklearn-env/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1531\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1459\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1460\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;124;03m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1531\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m _load_from_checkpoint(\n\u001b[1;32m   1532\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   1533\u001b[0m         checkpoint_path,\n\u001b[1;32m   1534\u001b[0m         map_location,\n\u001b[1;32m   1535\u001b[0m         hparams_file,\n\u001b[1;32m   1536\u001b[0m         strict,\n\u001b[1;32m   1537\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1538\u001b[0m     )\n\u001b[1;32m   1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/anaconda3/envs/sklearn-env/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:62\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     map_location \u001b[38;5;241m=\u001b[39m cast(_MAP_LOCATION_TYPE, \u001b[38;5;28;01mlambda\u001b[39;00m storage, loc: storage)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m---> 62\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m pl_load(checkpoint_path, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[1;32m     65\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[1;32m     66\u001b[0m     checkpoint, checkpoint_path\u001b[38;5;241m=\u001b[39m(checkpoint_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_path, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     67\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/sklearn-env/lib/python3.11/site-packages/lightning_fabric/utilities/cloud_io.py:50\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload_state_dict_from_url(\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28mstr\u001b[39m(path_or_url),\n\u001b[1;32m     47\u001b[0m         map_location\u001b[38;5;241m=\u001b[39mmap_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mopen(path_or_url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(f, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n",
      "File \u001b[0;32m~/anaconda3/envs/sklearn-env/lib/python3.11/site-packages/fsspec/spec.py:1154\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1153\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[0;32m-> 1154\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(\n\u001b[1;32m   1155\u001b[0m         path,\n\u001b[1;32m   1156\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   1157\u001b[0m         block_size\u001b[38;5;241m=\u001b[39mblock_size,\n\u001b[1;32m   1158\u001b[0m         autocommit\u001b[38;5;241m=\u001b[39mac,\n\u001b[1;32m   1159\u001b[0m         cache_options\u001b[38;5;241m=\u001b[39mcache_options,\n\u001b[1;32m   1160\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1161\u001b[0m     )\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/anaconda3/envs/sklearn-env/lib/python3.11/site-packages/fsspec/implementations/local.py:183\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/sklearn-env/lib/python3.11/site-packages/fsspec/implementations/local.py:287\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open()\n",
      "File \u001b[0;32m~/anaconda3/envs/sklearn-env/lib/python3.11/site-packages/fsspec/implementations/local.py:292\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m--> 292\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[1;32m    294\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/josephine/proj/auth_ident/authorship-embeddings/model/final_2022-06-15_08-10-17_lstm_blogs.ckpt'"
     ]
    }
   ],
   "source": [
    "from model import ContrastiveTransformer\n",
    "from random import shuffle\n",
    "\n",
    "REPEATS = 100\n",
    "TOP_K = 5\n",
    "DEVICE = 1\n",
    "\n",
    "n_list = [10, 20, 50, 100, 250]\n",
    "#keys = ['all', 'blogs', 'books', 'mails']\n",
    "keys = ['blogs', 'mails']\n",
    "\n",
    "data_dict = {}\n",
    "# Pass on trained models\n",
    "for k_model in keys:\n",
    "    model_ckpt = model_zoo[k_model]\n",
    "    model = ContrastiveTransformer.load_from_checkpoint(checkpoint_path=model_ckpt).cuda(DEVICE)\n",
    "\n",
    "    data_dict[f'Model_{k_model}'] = {}\n",
    "    print(f'[log] Evaluating model - {k_model}')\n",
    "\n",
    "    for k_data in keys:\n",
    "        data = data_zoo[k_data]\n",
    "        \n",
    "        data_dict[f'Model_{k_model}'][f'data_{k_data}'] = {}\n",
    "        print(f'[log] Evaluating on data - {k_data}')\n",
    "\n",
    "        for n in n_list:\n",
    "            print(f'[log] Running {REPEATS} repetitions for N={n}')\n",
    "            max_len = len(data.id.unique())\n",
    "            \n",
    "            if n == 'max':\n",
    "                n = max_len\n",
    "\n",
    "            if n <= max_len:\n",
    "                acc, topk, acc_sd, topk_sd = evaluate(model, data, top_k=TOP_K, N=n, repetitions=REPEATS)\n",
    "                data_dict[f'Model_{k_model}'][f'data_{k_data}'][f'N={n} Accuracy'] = f'{100*acc:.2f}% ± {100*acc_sd:.2f}'\n",
    "                data_dict[f'Model_{k_model}'][f'data_{k_data}'][f'N={n} Top-5 Accuracy'] = f'{100*topk:.2f}% ± {100*topk_sd:.2f}'\n",
    "\n",
    "                print(f'[log] model:{k_model}_data:{k_data}_n:{n}: {100*acc:.2f}% {100*topk:.2f}%')\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "model = AutoModel.from_pretrained('roberta-large').cuda(DEVICE)\n",
    "\n",
    "data_dict[f'Model_RoBERTa'] = {}\n",
    "print(f'[log] Evaluating model - RoBERTa')\n",
    "#Base transformer\n",
    "for k_data in keys:\n",
    "    data = data_zoo[k_data]\n",
    "        \n",
    "    data_dict[f'Model_{k_model}'][f'data_{k_data}'] = {}\n",
    "    print(f'[log] Evaluating on data - {k_data}')\n",
    "\n",
    "    for n in n_list:\n",
    "        print(f'[log] Running {REPEATS} repetitions for N={n}')\n",
    "        max_len = len(data.id.unique())\n",
    "        \n",
    "        if n == 'max':\n",
    "            n = max_len\n",
    "\n",
    "        if n <= max_len:\n",
    "            acc, topk, acc_sd, topk_sd = evaluate(model, data, top_k=TOP_K, N=n, repetitions=REPEATS, embed_f=embed_transformer)\n",
    "            data_dict[f'Model_{k_model}'][f'data_{k_data}'][f'N={n} Accuracy'] = f'{100*acc:.2f}% ± {100*acc_sd:.2f}'\n",
    "            data_dict[f'Model_{k_model}'][f'data_{k_data}'][f'N={n} Top-5 Accuracy'] = f'{100*topk:.2f}% ± {100*topk_sd:.2f}'\n",
    "\n",
    "            print(f'[log] model:{k_model}_data:{k_data}_n:{n}: {100*acc:.2f}% {100*topk:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_all</th>\n",
       "      <th>Model_blogs</th>\n",
       "      <th>Model_books</th>\n",
       "      <th>Model_mails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data_all</th>\n",
       "      <td>{'N=10 Accuracy': '91.25% ± 7.69', 'N=10 Top-5...</td>\n",
       "      <td>{'N=10 Accuracy': '90.35% ± 8.67', 'N=10 Top-5...</td>\n",
       "      <td>{'N=10 Accuracy': '58.25% ± 13.16', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '25.40% ± 11.48', 'N=10 Top-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_blogs</th>\n",
       "      <td>{'N=10 Accuracy': '90.60% ± 8.90', 'N=10 Top-5...</td>\n",
       "      <td>{'N=10 Accuracy': '91.55% ± 8.21', 'N=10 Top-5...</td>\n",
       "      <td>{'N=10 Accuracy': '52.60% ± 13.59', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '21.30% ± 10.38', 'N=10 Top-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_books</th>\n",
       "      <td>{'N=10 Accuracy': '87.75% ± 10.08', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '64.15% ± 12.71', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '83.50% ± 11.15', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '26.90% ± 12.22', 'N=10 Top-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_mails</th>\n",
       "      <td>{'N=10 Accuracy': '28.65% ± 9.79', 'N=10 Top-5...</td>\n",
       "      <td>{'N=10 Accuracy': '26.25% ± 11.76', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '21.80% ± 10.62', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '24.90% ± 12.43', 'N=10 Top-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Model_all  \\\n",
       "data_all    {'N=10 Accuracy': '91.25% ± 7.69', 'N=10 Top-5...   \n",
       "data_blogs  {'N=10 Accuracy': '90.60% ± 8.90', 'N=10 Top-5...   \n",
       "data_books  {'N=10 Accuracy': '87.75% ± 10.08', 'N=10 Top-...   \n",
       "data_mails  {'N=10 Accuracy': '28.65% ± 9.79', 'N=10 Top-5...   \n",
       "\n",
       "                                                  Model_blogs  \\\n",
       "data_all    {'N=10 Accuracy': '90.35% ± 8.67', 'N=10 Top-5...   \n",
       "data_blogs  {'N=10 Accuracy': '91.55% ± 8.21', 'N=10 Top-5...   \n",
       "data_books  {'N=10 Accuracy': '64.15% ± 12.71', 'N=10 Top-...   \n",
       "data_mails  {'N=10 Accuracy': '26.25% ± 11.76', 'N=10 Top-...   \n",
       "\n",
       "                                                  Model_books  \\\n",
       "data_all    {'N=10 Accuracy': '58.25% ± 13.16', 'N=10 Top-...   \n",
       "data_blogs  {'N=10 Accuracy': '52.60% ± 13.59', 'N=10 Top-...   \n",
       "data_books  {'N=10 Accuracy': '83.50% ± 11.15', 'N=10 Top-...   \n",
       "data_mails  {'N=10 Accuracy': '21.80% ± 10.62', 'N=10 Top-...   \n",
       "\n",
       "                                                  Model_mails  \n",
       "data_all    {'N=10 Accuracy': '25.40% ± 11.48', 'N=10 Top-...  \n",
       "data_blogs  {'N=10 Accuracy': '21.30% ± 10.38', 'N=10 Top-...  \n",
       "data_books  {'N=10 Accuracy': '26.90% ± 12.22', 'N=10 Top-...  \n",
       "data_mails  {'N=10 Accuracy': '24.90% ± 12.43', 'N=10 Top-...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results/tests_summary.json', 'w') as f:\n",
    "    json.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results/tests_summary.json', 'r') as f:\n",
    "    data_dict = json.load(f)\n",
    "\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_all</th>\n",
       "      <th>data_blogs</th>\n",
       "      <th>data_books</th>\n",
       "      <th>data_mails</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N=10 Accuracy</th>\n",
       "      <td>91.25% ± 7.69</td>\n",
       "      <td>90.60% ± 8.90</td>\n",
       "      <td>87.75% ± 10.08</td>\n",
       "      <td>28.65% ± 9.79</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Top-5 Accuracy</th>\n",
       "      <td>98.35% ± 3.47</td>\n",
       "      <td>98.25% ± 4.02</td>\n",
       "      <td>98.85% ± 3.31</td>\n",
       "      <td>68.85% ± 10.02</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Accuracy</th>\n",
       "      <td>86.60% ± 7.16</td>\n",
       "      <td>88.08% ± 6.68</td>\n",
       "      <td>81.45% ± 7.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Top-5 Accuracy</th>\n",
       "      <td>95.40% ± 4.28</td>\n",
       "      <td>96.70% ± 3.59</td>\n",
       "      <td>96.28% ± 3.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Accuracy</th>\n",
       "      <td>83.72% ± 4.60</td>\n",
       "      <td>82.51% ± 4.78</td>\n",
       "      <td>72.14% ± 5.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Top-5 Accuracy</th>\n",
       "      <td>93.73% ± 3.54</td>\n",
       "      <td>93.13% ± 3.58</td>\n",
       "      <td>91.94% ± 3.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Accuracy</th>\n",
       "      <td>78.39% ± 3.99</td>\n",
       "      <td>77.95% ± 3.95</td>\n",
       "      <td>65.07% ± 3.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Top-5 Accuracy</th>\n",
       "      <td>90.84% ± 2.55</td>\n",
       "      <td>90.14% ± 2.90</td>\n",
       "      <td>86.49% ± 2.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Accuracy</th>\n",
       "      <td>72.39% ± 2.39</td>\n",
       "      <td>71.56% ± 2.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Top-5 Accuracy</th>\n",
       "      <td>86.73% ± 2.07</td>\n",
       "      <td>85.77% ± 1.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Accuracy</th>\n",
       "      <td>90.35% ± 8.67</td>\n",
       "      <td>91.55% ± 8.21</td>\n",
       "      <td>64.15% ± 12.71</td>\n",
       "      <td>26.25% ± 11.76</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Top-5 Accuracy</th>\n",
       "      <td>97.55% ± 4.50</td>\n",
       "      <td>97.75% ± 4.49</td>\n",
       "      <td>92.75% ± 6.72</td>\n",
       "      <td>67.65% ± 13.52</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Accuracy</th>\n",
       "      <td>86.67% ± 7.81</td>\n",
       "      <td>87.68% ± 7.95</td>\n",
       "      <td>56.17% ± 9.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Top-5 Accuracy</th>\n",
       "      <td>96.10% ± 3.99</td>\n",
       "      <td>96.05% ± 3.97</td>\n",
       "      <td>85.32% ± 6.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Accuracy</th>\n",
       "      <td>82.22% ± 5.16</td>\n",
       "      <td>82.07% ± 4.16</td>\n",
       "      <td>43.74% ± 5.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Top-5 Accuracy</th>\n",
       "      <td>93.16% ± 3.60</td>\n",
       "      <td>92.99% ± 3.19</td>\n",
       "      <td>70.78% ± 5.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Accuracy</th>\n",
       "      <td>77.37% ± 3.94</td>\n",
       "      <td>77.73% ± 3.86</td>\n",
       "      <td>35.94% ± 3.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Top-5 Accuracy</th>\n",
       "      <td>90.39% ± 2.99</td>\n",
       "      <td>90.00% ± 2.89</td>\n",
       "      <td>60.44% ± 4.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Accuracy</th>\n",
       "      <td>70.51% ± 2.74</td>\n",
       "      <td>71.11% ± 2.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Top-5 Accuracy</th>\n",
       "      <td>85.65% ± 2.19</td>\n",
       "      <td>85.50% ± 2.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Accuracy</th>\n",
       "      <td>58.25% ± 13.16</td>\n",
       "      <td>52.60% ± 13.59</td>\n",
       "      <td>83.50% ± 11.15</td>\n",
       "      <td>21.80% ± 10.62</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Top-5 Accuracy</th>\n",
       "      <td>88.85% ± 9.38</td>\n",
       "      <td>87.35% ± 8.84</td>\n",
       "      <td>96.75% ± 4.82</td>\n",
       "      <td>63.40% ± 11.51</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Accuracy</th>\n",
       "      <td>45.98% ± 11.06</td>\n",
       "      <td>41.62% ± 9.77</td>\n",
       "      <td>77.92% ± 8.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Top-5 Accuracy</th>\n",
       "      <td>76.40% ± 8.26</td>\n",
       "      <td>73.10% ± 9.04</td>\n",
       "      <td>93.40% ± 4.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Accuracy</th>\n",
       "      <td>34.93% ± 6.33</td>\n",
       "      <td>30.62% ± 5.84</td>\n",
       "      <td>70.10% ± 6.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Top-5 Accuracy</th>\n",
       "      <td>62.19% ± 5.96</td>\n",
       "      <td>57.20% ± 6.55</td>\n",
       "      <td>89.28% ± 3.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Accuracy</th>\n",
       "      <td>28.06% ± 4.26</td>\n",
       "      <td>24.88% ± 3.35</td>\n",
       "      <td>61.38% ± 4.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Top-5 Accuracy</th>\n",
       "      <td>50.18% ± 4.94</td>\n",
       "      <td>47.44% ± 4.13</td>\n",
       "      <td>83.51% ± 2.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Accuracy</th>\n",
       "      <td>20.90% ± 2.09</td>\n",
       "      <td>17.05% ± 1.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Top-5 Accuracy</th>\n",
       "      <td>38.08% ± 2.73</td>\n",
       "      <td>33.81% ± 2.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Accuracy</th>\n",
       "      <td>25.40% ± 11.48</td>\n",
       "      <td>21.30% ± 10.38</td>\n",
       "      <td>26.90% ± 12.22</td>\n",
       "      <td>24.90% ± 12.43</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Top-5 Accuracy</th>\n",
       "      <td>70.40% ± 14.10</td>\n",
       "      <td>68.10% ± 14.40</td>\n",
       "      <td>70.55% ± 10.84</td>\n",
       "      <td>68.80% ± 12.65</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Accuracy</th>\n",
       "      <td>18.40% ± 8.76</td>\n",
       "      <td>13.77% ± 6.26</td>\n",
       "      <td>16.93% ± 7.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Top-5 Accuracy</th>\n",
       "      <td>47.82% ± 11.84</td>\n",
       "      <td>42.43% ± 9.20</td>\n",
       "      <td>48.10% ± 9.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Accuracy</th>\n",
       "      <td>10.47% ± 4.12</td>\n",
       "      <td>8.56% ± 3.42</td>\n",
       "      <td>8.94% ± 3.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Top-5 Accuracy</th>\n",
       "      <td>28.72% ± 6.13</td>\n",
       "      <td>24.13% ± 5.72</td>\n",
       "      <td>27.94% ± 4.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Accuracy</th>\n",
       "      <td>6.84% ± 1.87</td>\n",
       "      <td>5.47% ± 2.13</td>\n",
       "      <td>6.29% ± 2.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Top-5 Accuracy</th>\n",
       "      <td>19.39% ± 3.83</td>\n",
       "      <td>15.86% ± 3.45</td>\n",
       "      <td>18.55% ± 3.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Accuracy</th>\n",
       "      <td>4.27% ± 1.06</td>\n",
       "      <td>3.05% ± 0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Top-5 Accuracy</th>\n",
       "      <td>11.87% ± 1.69</td>\n",
       "      <td>8.95% ± 1.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Accuracy</th>\n",
       "      <td>44.65% ± 15.02</td>\n",
       "      <td>39.20% ± 13.61</td>\n",
       "      <td>44.05% ± 13.98</td>\n",
       "      <td>23.85% ± 10.46</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Top-5 Accuracy</th>\n",
       "      <td>76.55% ± 11.24</td>\n",
       "      <td>72.50% ± 9.39</td>\n",
       "      <td>77.90% ± 10.82</td>\n",
       "      <td>63.00% ± 11.45</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Accuracy</th>\n",
       "      <td>36.95% ± 10.37</td>\n",
       "      <td>34.42% ± 8.93</td>\n",
       "      <td>37.15% ± 9.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Top-5 Accuracy</th>\n",
       "      <td>61.33% ± 9.41</td>\n",
       "      <td>58.30% ± 8.56</td>\n",
       "      <td>63.62% ± 8.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Accuracy</th>\n",
       "      <td>27.65% ± 5.61</td>\n",
       "      <td>24.53% ± 4.80</td>\n",
       "      <td>28.91% ± 6.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Top-5 Accuracy</th>\n",
       "      <td>45.89% ± 6.49</td>\n",
       "      <td>41.34% ± 6.19</td>\n",
       "      <td>50.39% ± 6.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Accuracy</th>\n",
       "      <td>23.30% ± 4.01</td>\n",
       "      <td>21.30% ± 3.82</td>\n",
       "      <td>24.23% ± 3.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Top-5 Accuracy</th>\n",
       "      <td>38.09% ± 4.46</td>\n",
       "      <td>34.96% ± 4.17</td>\n",
       "      <td>42.11% ± 3.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Accuracy</th>\n",
       "      <td>18.77% ± 1.99</td>\n",
       "      <td>16.76% ± 1.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Top-5 Accuracy</th>\n",
       "      <td>30.03% ± 2.29</td>\n",
       "      <td>26.94% ± 2.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            data_all      data_blogs      data_books  \\\n",
       "N=10 Accuracy          91.25% ± 7.69   90.60% ± 8.90  87.75% ± 10.08   \n",
       "N=10 Top-5 Accuracy    98.35% ± 3.47   98.25% ± 4.02   98.85% ± 3.31   \n",
       "N=20 Accuracy          86.60% ± 7.16   88.08% ± 6.68   81.45% ± 7.21   \n",
       "N=20 Top-5 Accuracy    95.40% ± 4.28   96.70% ± 3.59   96.28% ± 3.86   \n",
       "N=50 Accuracy          83.72% ± 4.60   82.51% ± 4.78   72.14% ± 5.34   \n",
       "N=50 Top-5 Accuracy    93.73% ± 3.54   93.13% ± 3.58   91.94% ± 3.26   \n",
       "N=100 Accuracy         78.39% ± 3.99   77.95% ± 3.95   65.07% ± 3.89   \n",
       "N=100 Top-5 Accuracy   90.84% ± 2.55   90.14% ± 2.90   86.49% ± 2.81   \n",
       "N=250 Accuracy         72.39% ± 2.39   71.56% ± 2.45             NaN   \n",
       "N=250 Top-5 Accuracy   86.73% ± 2.07   85.77% ± 1.92             NaN   \n",
       "N=10 Accuracy          90.35% ± 8.67   91.55% ± 8.21  64.15% ± 12.71   \n",
       "N=10 Top-5 Accuracy    97.55% ± 4.50   97.75% ± 4.49   92.75% ± 6.72   \n",
       "N=20 Accuracy          86.67% ± 7.81   87.68% ± 7.95   56.17% ± 9.49   \n",
       "N=20 Top-5 Accuracy    96.10% ± 3.99   96.05% ± 3.97   85.32% ± 6.56   \n",
       "N=50 Accuracy          82.22% ± 5.16   82.07% ± 4.16   43.74% ± 5.90   \n",
       "N=50 Top-5 Accuracy    93.16% ± 3.60   92.99% ± 3.19   70.78% ± 5.69   \n",
       "N=100 Accuracy         77.37% ± 3.94   77.73% ± 3.86   35.94% ± 3.69   \n",
       "N=100 Top-5 Accuracy   90.39% ± 2.99   90.00% ± 2.89   60.44% ± 4.05   \n",
       "N=250 Accuracy         70.51% ± 2.74   71.11% ± 2.78             NaN   \n",
       "N=250 Top-5 Accuracy   85.65% ± 2.19   85.50% ± 2.20             NaN   \n",
       "N=10 Accuracy         58.25% ± 13.16  52.60% ± 13.59  83.50% ± 11.15   \n",
       "N=10 Top-5 Accuracy    88.85% ± 9.38   87.35% ± 8.84   96.75% ± 4.82   \n",
       "N=20 Accuracy         45.98% ± 11.06   41.62% ± 9.77   77.92% ± 8.70   \n",
       "N=20 Top-5 Accuracy    76.40% ± 8.26   73.10% ± 9.04   93.40% ± 4.70   \n",
       "N=50 Accuracy          34.93% ± 6.33   30.62% ± 5.84   70.10% ± 6.62   \n",
       "N=50 Top-5 Accuracy    62.19% ± 5.96   57.20% ± 6.55   89.28% ± 3.78   \n",
       "N=100 Accuracy         28.06% ± 4.26   24.88% ± 3.35   61.38% ± 4.34   \n",
       "N=100 Top-5 Accuracy   50.18% ± 4.94   47.44% ± 4.13   83.51% ± 2.92   \n",
       "N=250 Accuracy         20.90% ± 2.09   17.05% ± 1.96             NaN   \n",
       "N=250 Top-5 Accuracy   38.08% ± 2.73   33.81% ± 2.44             NaN   \n",
       "N=10 Accuracy         25.40% ± 11.48  21.30% ± 10.38  26.90% ± 12.22   \n",
       "N=10 Top-5 Accuracy   70.40% ± 14.10  68.10% ± 14.40  70.55% ± 10.84   \n",
       "N=20 Accuracy          18.40% ± 8.76   13.77% ± 6.26   16.93% ± 7.38   \n",
       "N=20 Top-5 Accuracy   47.82% ± 11.84   42.43% ± 9.20   48.10% ± 9.37   \n",
       "N=50 Accuracy          10.47% ± 4.12    8.56% ± 3.42    8.94% ± 3.49   \n",
       "N=50 Top-5 Accuracy    28.72% ± 6.13   24.13% ± 5.72   27.94% ± 4.98   \n",
       "N=100 Accuracy          6.84% ± 1.87    5.47% ± 2.13    6.29% ± 2.05   \n",
       "N=100 Top-5 Accuracy   19.39% ± 3.83   15.86% ± 3.45   18.55% ± 3.64   \n",
       "N=250 Accuracy          4.27% ± 1.06    3.05% ± 0.89             NaN   \n",
       "N=250 Top-5 Accuracy   11.87% ± 1.69    8.95% ± 1.53             NaN   \n",
       "N=10 Accuracy         44.65% ± 15.02  39.20% ± 13.61  44.05% ± 13.98   \n",
       "N=10 Top-5 Accuracy   76.55% ± 11.24   72.50% ± 9.39  77.90% ± 10.82   \n",
       "N=20 Accuracy         36.95% ± 10.37   34.42% ± 8.93   37.15% ± 9.89   \n",
       "N=20 Top-5 Accuracy    61.33% ± 9.41   58.30% ± 8.56   63.62% ± 8.03   \n",
       "N=50 Accuracy          27.65% ± 5.61   24.53% ± 4.80   28.91% ± 6.14   \n",
       "N=50 Top-5 Accuracy    45.89% ± 6.49   41.34% ± 6.19   50.39% ± 6.47   \n",
       "N=100 Accuracy         23.30% ± 4.01   21.30% ± 3.82   24.23% ± 3.31   \n",
       "N=100 Top-5 Accuracy   38.09% ± 4.46   34.96% ± 4.17   42.11% ± 3.73   \n",
       "N=250 Accuracy         18.77% ± 1.99   16.76% ± 1.86             NaN   \n",
       "N=250 Top-5 Accuracy   30.03% ± 2.29   26.94% ± 2.49             NaN   \n",
       "\n",
       "                          data_mails          Model  \n",
       "N=10 Accuracy          28.65% ± 9.79      Model_all  \n",
       "N=10 Top-5 Accuracy   68.85% ± 10.02      Model_all  \n",
       "N=20 Accuracy                    NaN      Model_all  \n",
       "N=20 Top-5 Accuracy              NaN      Model_all  \n",
       "N=50 Accuracy                    NaN      Model_all  \n",
       "N=50 Top-5 Accuracy              NaN      Model_all  \n",
       "N=100 Accuracy                   NaN      Model_all  \n",
       "N=100 Top-5 Accuracy             NaN      Model_all  \n",
       "N=250 Accuracy                   NaN      Model_all  \n",
       "N=250 Top-5 Accuracy             NaN      Model_all  \n",
       "N=10 Accuracy         26.25% ± 11.76    Model_blogs  \n",
       "N=10 Top-5 Accuracy   67.65% ± 13.52    Model_blogs  \n",
       "N=20 Accuracy                    NaN    Model_blogs  \n",
       "N=20 Top-5 Accuracy              NaN    Model_blogs  \n",
       "N=50 Accuracy                    NaN    Model_blogs  \n",
       "N=50 Top-5 Accuracy              NaN    Model_blogs  \n",
       "N=100 Accuracy                   NaN    Model_blogs  \n",
       "N=100 Top-5 Accuracy             NaN    Model_blogs  \n",
       "N=250 Accuracy                   NaN    Model_blogs  \n",
       "N=250 Top-5 Accuracy             NaN    Model_blogs  \n",
       "N=10 Accuracy         21.80% ± 10.62    Model_books  \n",
       "N=10 Top-5 Accuracy   63.40% ± 11.51    Model_books  \n",
       "N=20 Accuracy                    NaN    Model_books  \n",
       "N=20 Top-5 Accuracy              NaN    Model_books  \n",
       "N=50 Accuracy                    NaN    Model_books  \n",
       "N=50 Top-5 Accuracy              NaN    Model_books  \n",
       "N=100 Accuracy                   NaN    Model_books  \n",
       "N=100 Top-5 Accuracy             NaN    Model_books  \n",
       "N=250 Accuracy                   NaN    Model_books  \n",
       "N=250 Top-5 Accuracy             NaN    Model_books  \n",
       "N=10 Accuracy         24.90% ± 12.43    Model_mails  \n",
       "N=10 Top-5 Accuracy   68.80% ± 12.65    Model_mails  \n",
       "N=20 Accuracy                    NaN    Model_mails  \n",
       "N=20 Top-5 Accuracy              NaN    Model_mails  \n",
       "N=50 Accuracy                    NaN    Model_mails  \n",
       "N=50 Top-5 Accuracy              NaN    Model_mails  \n",
       "N=100 Accuracy                   NaN    Model_mails  \n",
       "N=100 Top-5 Accuracy             NaN    Model_mails  \n",
       "N=250 Accuracy                   NaN    Model_mails  \n",
       "N=250 Top-5 Accuracy             NaN    Model_mails  \n",
       "N=10 Accuracy         23.85% ± 10.46  Model_RoBERTa  \n",
       "N=10 Top-5 Accuracy   63.00% ± 11.45  Model_RoBERTa  \n",
       "N=20 Accuracy                    NaN  Model_RoBERTa  \n",
       "N=20 Top-5 Accuracy              NaN  Model_RoBERTa  \n",
       "N=50 Accuracy                    NaN  Model_RoBERTa  \n",
       "N=50 Top-5 Accuracy              NaN  Model_RoBERTa  \n",
       "N=100 Accuracy                   NaN  Model_RoBERTa  \n",
       "N=100 Top-5 Accuracy             NaN  Model_RoBERTa  \n",
       "N=250 Accuracy                   NaN  Model_RoBERTa  \n",
       "N=250 Top-5 Accuracy             NaN  Model_RoBERTa  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.DataFrame()\n",
    "for model, d in data_dict.items():\n",
    "    sub_frame = pd.DataFrame(d)\n",
    "    sub_frame['Model'] = model\n",
    "\n",
    "    dataframe = pd.concat([dataframe, sub_frame], axis=0)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "              &                      &        data\\_all &      data\\_blogs &      data\\_books &      data\\_mails \\\\\n",
      "Model & index &                 &                 &                 &                 \\\\\n",
      "\\midrule\n",
      "Model\\_all & N=10 Accuracy &   91.25\\% ± 7.69 &   90.60\\% ± 8.90 &  87.75\\% ± 10.08 &   28.65\\% ± 9.79 \\\\\n",
      "              & N=10 Top-5 Accuracy &   98.35\\% ± 3.47 &   98.25\\% ± 4.02 &   98.85\\% ± 3.31 &  68.85\\% ± 10.02 \\\\\n",
      "              & N=20 Accuracy &   86.60\\% ± 7.16 &   88.08\\% ± 6.68 &   81.45\\% ± 7.21 &             NaN \\\\\n",
      "              & N=20 Top-5 Accuracy &   95.40\\% ± 4.28 &   96.70\\% ± 3.59 &   96.28\\% ± 3.86 &             NaN \\\\\n",
      "              & N=50 Accuracy &   83.72\\% ± 4.60 &   82.51\\% ± 4.78 &   72.14\\% ± 5.34 &             NaN \\\\\n",
      "              & N=50 Top-5 Accuracy &   93.73\\% ± 3.54 &   93.13\\% ± 3.58 &   91.94\\% ± 3.26 &             NaN \\\\\n",
      "              & N=100 Accuracy &   78.39\\% ± 3.99 &   77.95\\% ± 3.95 &   65.07\\% ± 3.89 &             NaN \\\\\n",
      "              & N=100 Top-5 Accuracy &   90.84\\% ± 2.55 &   90.14\\% ± 2.90 &   86.49\\% ± 2.81 &             NaN \\\\\n",
      "              & N=250 Accuracy &   72.39\\% ± 2.39 &   71.56\\% ± 2.45 &             NaN &             NaN \\\\\n",
      "              & N=250 Top-5 Accuracy &   86.73\\% ± 2.07 &   85.77\\% ± 1.92 &             NaN &             NaN \\\\\n",
      "Model\\_blogs & N=10 Accuracy &   90.35\\% ± 8.67 &   91.55\\% ± 8.21 &  64.15\\% ± 12.71 &  26.25\\% ± 11.76 \\\\\n",
      "              & N=10 Top-5 Accuracy &   97.55\\% ± 4.50 &   97.75\\% ± 4.49 &   92.75\\% ± 6.72 &  67.65\\% ± 13.52 \\\\\n",
      "              & N=20 Accuracy &   86.67\\% ± 7.81 &   87.68\\% ± 7.95 &   56.17\\% ± 9.49 &             NaN \\\\\n",
      "              & N=20 Top-5 Accuracy &   96.10\\% ± 3.99 &   96.05\\% ± 3.97 &   85.32\\% ± 6.56 &             NaN \\\\\n",
      "              & N=50 Accuracy &   82.22\\% ± 5.16 &   82.07\\% ± 4.16 &   43.74\\% ± 5.90 &             NaN \\\\\n",
      "              & N=50 Top-5 Accuracy &   93.16\\% ± 3.60 &   92.99\\% ± 3.19 &   70.78\\% ± 5.69 &             NaN \\\\\n",
      "              & N=100 Accuracy &   77.37\\% ± 3.94 &   77.73\\% ± 3.86 &   35.94\\% ± 3.69 &             NaN \\\\\n",
      "              & N=100 Top-5 Accuracy &   90.39\\% ± 2.99 &   90.00\\% ± 2.89 &   60.44\\% ± 4.05 &             NaN \\\\\n",
      "              & N=250 Accuracy &   70.51\\% ± 2.74 &   71.11\\% ± 2.78 &             NaN &             NaN \\\\\n",
      "              & N=250 Top-5 Accuracy &   85.65\\% ± 2.19 &   85.50\\% ± 2.20 &             NaN &             NaN \\\\\n",
      "Model\\_books & N=10 Accuracy &  58.25\\% ± 13.16 &  52.60\\% ± 13.59 &  83.50\\% ± 11.15 &  21.80\\% ± 10.62 \\\\\n",
      "              & N=10 Top-5 Accuracy &   88.85\\% ± 9.38 &   87.35\\% ± 8.84 &   96.75\\% ± 4.82 &  63.40\\% ± 11.51 \\\\\n",
      "              & N=20 Accuracy &  45.98\\% ± 11.06 &   41.62\\% ± 9.77 &   77.92\\% ± 8.70 &             NaN \\\\\n",
      "              & N=20 Top-5 Accuracy &   76.40\\% ± 8.26 &   73.10\\% ± 9.04 &   93.40\\% ± 4.70 &             NaN \\\\\n",
      "              & N=50 Accuracy &   34.93\\% ± 6.33 &   30.62\\% ± 5.84 &   70.10\\% ± 6.62 &             NaN \\\\\n",
      "              & N=50 Top-5 Accuracy &   62.19\\% ± 5.96 &   57.20\\% ± 6.55 &   89.28\\% ± 3.78 &             NaN \\\\\n",
      "              & N=100 Accuracy &   28.06\\% ± 4.26 &   24.88\\% ± 3.35 &   61.38\\% ± 4.34 &             NaN \\\\\n",
      "              & N=100 Top-5 Accuracy &   50.18\\% ± 4.94 &   47.44\\% ± 4.13 &   83.51\\% ± 2.92 &             NaN \\\\\n",
      "              & N=250 Accuracy &   20.90\\% ± 2.09 &   17.05\\% ± 1.96 &             NaN &             NaN \\\\\n",
      "              & N=250 Top-5 Accuracy &   38.08\\% ± 2.73 &   33.81\\% ± 2.44 &             NaN &             NaN \\\\\n",
      "Model\\_mails & N=10 Accuracy &  25.40\\% ± 11.48 &  21.30\\% ± 10.38 &  26.90\\% ± 12.22 &  24.90\\% ± 12.43 \\\\\n",
      "              & N=10 Top-5 Accuracy &  70.40\\% ± 14.10 &  68.10\\% ± 14.40 &  70.55\\% ± 10.84 &  68.80\\% ± 12.65 \\\\\n",
      "              & N=20 Accuracy &   18.40\\% ± 8.76 &   13.77\\% ± 6.26 &   16.93\\% ± 7.38 &             NaN \\\\\n",
      "              & N=20 Top-5 Accuracy &  47.82\\% ± 11.84 &   42.43\\% ± 9.20 &   48.10\\% ± 9.37 &             NaN \\\\\n",
      "              & N=50 Accuracy &   10.47\\% ± 4.12 &    8.56\\% ± 3.42 &    8.94\\% ± 3.49 &             NaN \\\\\n",
      "              & N=50 Top-5 Accuracy &   28.72\\% ± 6.13 &   24.13\\% ± 5.72 &   27.94\\% ± 4.98 &             NaN \\\\\n",
      "              & N=100 Accuracy &    6.84\\% ± 1.87 &    5.47\\% ± 2.13 &    6.29\\% ± 2.05 &             NaN \\\\\n",
      "              & N=100 Top-5 Accuracy &   19.39\\% ± 3.83 &   15.86\\% ± 3.45 &   18.55\\% ± 3.64 &             NaN \\\\\n",
      "              & N=250 Accuracy &    4.27\\% ± 1.06 &    3.05\\% ± 0.89 &             NaN &             NaN \\\\\n",
      "              & N=250 Top-5 Accuracy &   11.87\\% ± 1.69 &    8.95\\% ± 1.53 &             NaN &             NaN \\\\\n",
      "Model\\_RoBERTa & N=10 Accuracy &  44.65\\% ± 15.02 &  39.20\\% ± 13.61 &  44.05\\% ± 13.98 &  23.85\\% ± 10.46 \\\\\n",
      "              & N=10 Top-5 Accuracy &  76.55\\% ± 11.24 &   72.50\\% ± 9.39 &  77.90\\% ± 10.82 &  63.00\\% ± 11.45 \\\\\n",
      "              & N=20 Accuracy &  36.95\\% ± 10.37 &   34.42\\% ± 8.93 &   37.15\\% ± 9.89 &             NaN \\\\\n",
      "              & N=20 Top-5 Accuracy &   61.33\\% ± 9.41 &   58.30\\% ± 8.56 &   63.62\\% ± 8.03 &             NaN \\\\\n",
      "              & N=50 Accuracy &   27.65\\% ± 5.61 &   24.53\\% ± 4.80 &   28.91\\% ± 6.14 &             NaN \\\\\n",
      "              & N=50 Top-5 Accuracy &   45.89\\% ± 6.49 &   41.34\\% ± 6.19 &   50.39\\% ± 6.47 &             NaN \\\\\n",
      "              & N=100 Accuracy &   23.30\\% ± 4.01 &   21.30\\% ± 3.82 &   24.23\\% ± 3.31 &             NaN \\\\\n",
      "              & N=100 Top-5 Accuracy &   38.09\\% ± 4.46 &   34.96\\% ± 4.17 &   42.11\\% ± 3.73 &             NaN \\\\\n",
      "              & N=250 Accuracy &   18.77\\% ± 1.99 &   16.76\\% ± 1.86 &             NaN &             NaN \\\\\n",
      "              & N=250 Top-5 Accuracy &   30.03\\% ± 2.29 &   26.94\\% ± 2.49 &             NaN &             NaN \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1586346/2621851513.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(dataframe.reset_index().set_index(['Model','index']).to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.reset_index().set_index(['Model','index']).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] Evaluating model - RoBERTa\n",
      "[log] Evaluating on data - all\n",
      "[log] Running 100 repetitions for N=10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ed23e53a084f9f8fc2f6bde4afc715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:all_n:10: 44.65% 76.55%\n",
      "[log] Running 100 repetitions for N=20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351fae5593224adba12d551e70b0452c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:all_n:20: 36.95% 61.33%\n",
      "[log] Running 100 repetitions for N=50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3efdd2eabc46a6b6ee106847a3ec8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:all_n:50: 27.65% 45.89%\n",
      "[log] Running 100 repetitions for N=100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b43327d3f874ba488564077105cbad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:all_n:100: 23.30% 38.09%\n",
      "[log] Running 100 repetitions for N=250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88163de980c142c8b780107554212f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:all_n:250: 18.77% 30.03%\n",
      "[log] Evaluating on data - blogs\n",
      "[log] Running 100 repetitions for N=10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fc0e036b634b3ba02ed37202922a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:blogs_n:10: 39.20% 72.50%\n",
      "[log] Running 100 repetitions for N=20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b8089e31d4483e8c07ceb1a7f82680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:blogs_n:20: 34.42% 58.30%\n",
      "[log] Running 100 repetitions for N=50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858eb336ebcb45c791cdb064ebbfbc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:blogs_n:50: 24.53% 41.34%\n",
      "[log] Running 100 repetitions for N=100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02cf68d8c174f8aa087e347c129d1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:blogs_n:100: 21.30% 34.96%\n",
      "[log] Running 100 repetitions for N=250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10217ac1aef94c03a3842e1411747fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:blogs_n:250: 16.76% 26.94%\n",
      "[log] Evaluating on data - books\n",
      "[log] Running 100 repetitions for N=10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69a04cf12eb44c091a57e4e25a10e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:books_n:10: 44.05% 77.90%\n",
      "[log] Running 100 repetitions for N=20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dad6bfa93ef48f4a2e2734ab6a99768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:books_n:20: 37.15% 63.62%\n",
      "[log] Running 100 repetitions for N=50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788928e8ff8d4ae7b803316989cbddb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:books_n:50: 28.91% 50.39%\n",
      "[log] Running 100 repetitions for N=100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ca8fac90774371bea98f92f3837aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:books_n:100: 24.23% 42.11%\n",
      "[log] Running 100 repetitions for N=250\n",
      "[log] Evaluating on data - mails\n",
      "[log] Running 100 repetitions for N=10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47665a46e8e64f5491aba5d75698bb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:mails_n:10: 23.85% 63.00%\n",
      "[log] Running 100 repetitions for N=20\n",
      "[log] Running 100 repetitions for N=50\n",
      "[log] Running 100 repetitions for N=100\n",
      "[log] Running 100 repetitions for N=250\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "DEVICE = 1\n",
    "REPEATS = 100\n",
    "TOP_K = 5\n",
    "\n",
    "n_list = [10, 20, 50, 100, 250]\n",
    "keys = ['all', 'blogs', 'books', 'mails']\n",
    "\n",
    "model = AutoModel.from_pretrained('roberta-large').cuda(DEVICE)\n",
    "\n",
    "data_dict[f'Model_RoBERTa'] = {}\n",
    "print(f'[log] Evaluating model - RoBERTa')\n",
    "\n",
    "for k_data in keys:\n",
    "    data = data_zoo[k_data]\n",
    "        \n",
    "    data_dict[f'Model_RoBERTa'][f'data_{k_data}'] = {}\n",
    "    print(f'[log] Evaluating on data - {k_data}')\n",
    "\n",
    "    for n in n_list:\n",
    "        print(f'[log] Running {REPEATS} repetitions for N={n}')\n",
    "        max_len = len(data.id.unique())\n",
    "        \n",
    "        if n == 'max':\n",
    "            n = max_len\n",
    "\n",
    "        if n <= max_len:\n",
    "            acc, topk, acc_sd, topk_sd = evaluate(model, data, top_k=TOP_K, N=n, repetitions=REPEATS, embed_f=embed_transformer)\n",
    "            data_dict[f'Model_RoBERTa'][f'data_{k_data}'][f'N={n} Accuracy'] = f'{100*acc:.2f}% ± {100*acc_sd:.2f}'\n",
    "            data_dict[f'Model_RoBERTa'][f'data_{k_data}'][f'N={n} Top-5 Accuracy'] = f'{100*topk:.2f}% ± {100*topk_sd:.2f}'\n",
    "\n",
    "            print(f'[log] model:RoBERTa_data:{k_data}_n:{n}: {100*acc:.2f}% {100*topk:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
