{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CHUNK_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def split_data(row):\n",
    "    eid, values = row\n",
    "    input_ids = tokenizer(values.text).input_ids\n",
    "    chunked = [input_ids[chunk: chunk + CHUNK_SIZE] for chunk in range(0, len(input_ids), CHUNK_SIZE)]\n",
    "    decoded_chunked = tokenizer.batch_decode(chunked)\n",
    "    return pd.DataFrame({'id': [eid]*len(chunked),\n",
    "                         'pretokenized_text': chunked,\n",
    "                         'decoded_text': decoded_chunked})\n",
    "                         \n",
    "def build_chunk_dataframe(text_data, metadata=None, cores=10):\n",
    "    with Pool(cores) as p:\n",
    "        chunks = list(tqdm(p.imap_unordered(split_data, text_data.iterrows()),\n",
    "                            total=len(text_data)))\n",
    "    \n",
    "    if metadata is not None:\n",
    "        return pd.concat(chunks).merge(metadata, on='id')\n",
    "    else:\n",
    "        return pd.concat(chunks)\n",
    "\n",
    "def clean_non_unique(data):\n",
    "    nunique_ids = (data.id.value_counts() > 1)\n",
    "    nunique_ids = nunique_ids[nunique_ids].index\n",
    "    return data[data.id.isin(nunique_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blog data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Load data blog_as_csv.csv')\n",
    "blog_corpus = pd.read_csv(\"data/nlp/blog_corpus/blog_as_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>gender</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blog_0</th>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "      <td>Info has been found (+/- 100 pages, and 4.5 MB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_1</th>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>male</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can now 'capture'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_10</th>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "      <td>Even though I am exhausted after today, I must...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_100</th>\n",
       "      <td>26</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "      <td>Hello again.  This is the offical No Action bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_1000</th>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "      <td>My 'band' got in its first fight tonight. most...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_9995</th>\n",
       "      <td>17</td>\n",
       "      <td>Communications-Media</td>\n",
       "      <td>male</td>\n",
       "      <td>Good morning folks,  How are me brothers and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_9996</th>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "      <td>NEWater   Ok, that's just gross.   Another pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_9997</th>\n",
       "      <td>26</td>\n",
       "      <td>Education</td>\n",
       "      <td>male</td>\n",
       "      <td>I love salsa. It's one of the greatest foods e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_9998</th>\n",
       "      <td>13</td>\n",
       "      <td>Law</td>\n",
       "      <td>male</td>\n",
       "      <td>Hey all, This is Jared, this is my first post ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blog_9999</th>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "      <td>On the underground in London, at rush hour, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age                 topic  gender  \\\n",
       "id                                             \n",
       "blog_0      15               Student    male   \n",
       "blog_1      33     InvestmentBanking    male   \n",
       "blog_10     25                indUnk  female   \n",
       "blog_100    26                indUnk    male   \n",
       "blog_1000   16               Student    male   \n",
       "...        ...                   ...     ...   \n",
       "blog_9995   17  Communications-Media    male   \n",
       "blog_9996   23                indUnk  female   \n",
       "blog_9997   26             Education    male   \n",
       "blog_9998   13                   Law    male   \n",
       "blog_9999   33                indUnk  female   \n",
       "\n",
       "                                                        text  \n",
       "id                                                            \n",
       "blog_0     Info has been found (+/- 100 pages, and 4.5 MB...  \n",
       "blog_1     Thanks to Yahoo!'s Toolbar I can now 'capture'...  \n",
       "blog_10    Even though I am exhausted after today, I must...  \n",
       "blog_100   Hello again.  This is the offical No Action bl...  \n",
       "blog_1000  My 'band' got in its first fight tonight. most...  \n",
       "...                                                      ...  \n",
       "blog_9995  Good morning folks,  How are me brothers and s...  \n",
       "blog_9996  NEWater   Ok, that's just gross.   Another pot...  \n",
       "blog_9997  I love salsa. It's one of the greatest foods e...  \n",
       "blog_9998  Hey all, This is Jared, this is my first post ...  \n",
       "blog_9999  On the underground in London, at rush hour, th...  \n",
       "\n",
       "[19320 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_corpus.text = blog_corpus.text.apply(lambda x: x.strip())\n",
    "clean_blog_corpus = blog_corpus[['id', 'text']].groupby(\"id\").agg(lambda x: '<\\s>'.join(x))\n",
    "meta_blog_corpus = blog_corpus[['id', 'age', 'topic', 'gender']].groupby(\"id\").agg(lambda x: list(x)[0])\n",
    "full_blog_corpus = meta_blog_corpus.merge(clean_blog_corpus, on='id')\n",
    "full_blog_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7834874141704c4f83aada41dd7e04f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pretokenized_text</th>\n",
       "      <th>decoded_text</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blog_10</td>\n",
       "      <td>[0, 8170, 600, 38, 524, 17067, 71, 452, 6, 38,...</td>\n",
       "      <td>&lt;s&gt;Even though I am exhausted after today, I m...</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blog_10</td>\n",
       "      <td>[216, 24, 4, 152, 7105, 16, 3680, 684, 25, 121...</td>\n",
       "      <td>know it. This hell is otherwise known as U Vi...</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blog_10</td>\n",
       "      <td>[17027, 12, 560, 12, 1610, 18, 2850, 12179, 33...</td>\n",
       "      <td>groom-to-be's scrotal bling, but not the Fout...</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blog_100</td>\n",
       "      <td>[0, 31414, 456, 4, 1437, 152, 16, 5, 160, 3569...</td>\n",
       "      <td>&lt;s&gt;Hello again.  This is the offical No Action...</td>\n",
       "      <td>26</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blog_100</td>\n",
       "      <td>[5, 7884, 20774, 29, 31, 14, 6, 25, 157, 25, 5...</td>\n",
       "      <td>the singalongs from that, as well as the mino...</td>\n",
       "      <td>26</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382132</th>\n",
       "      <td>blog_9660</td>\n",
       "      <td>[6, 53, 38, 174, 69, 52, 1017, 1153, 357, 2067...</td>\n",
       "      <td>, but I told her we'd probably better wait on ...</td>\n",
       "      <td>35</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382133</th>\n",
       "      <td>blog_9660</td>\n",
       "      <td>[6, 61, 16, 182, 9327, 4, 1437, 1437, 38, 21, ...</td>\n",
       "      <td>, which is very unfortunate.   I was pretty un...</td>\n",
       "      <td>35</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382134</th>\n",
       "      <td>blog_9660</td>\n",
       "      <td>[9, 5, 2859, 9572, 6, 30005, 24, 6, 8, 122, 52...</td>\n",
       "      <td>of the heat strip, disconnected it, and now w...</td>\n",
       "      <td>35</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382135</th>\n",
       "      <td>blog_9660</td>\n",
       "      <td>[24, 19, 162, 8, 3668, 19975, 24, 31509, 243, ...</td>\n",
       "      <td>it with me and absolutely hated it ('It's stu...</td>\n",
       "      <td>35</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382136</th>\n",
       "      <td>blog_9660</td>\n",
       "      <td>[9366, 6, 11954, 6, 132, 12, 19402, 9, 26108, ...</td>\n",
       "      <td>pizza, wings, 2-liter of Coke, etc... Pretty ...</td>\n",
       "      <td>35</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382024 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                  pretokenized_text  \\\n",
       "0         blog_10  [0, 8170, 600, 38, 524, 17067, 71, 452, 6, 38,...   \n",
       "1         blog_10  [216, 24, 4, 152, 7105, 16, 3680, 684, 25, 121...   \n",
       "2         blog_10  [17027, 12, 560, 12, 1610, 18, 2850, 12179, 33...   \n",
       "3        blog_100  [0, 31414, 456, 4, 1437, 152, 16, 5, 160, 3569...   \n",
       "4        blog_100  [5, 7884, 20774, 29, 31, 14, 6, 25, 157, 25, 5...   \n",
       "...           ...                                                ...   \n",
       "382132  blog_9660  [6, 53, 38, 174, 69, 52, 1017, 1153, 357, 2067...   \n",
       "382133  blog_9660  [6, 61, 16, 182, 9327, 4, 1437, 1437, 38, 21, ...   \n",
       "382134  blog_9660  [9, 5, 2859, 9572, 6, 30005, 24, 6, 8, 122, 52...   \n",
       "382135  blog_9660  [24, 19, 162, 8, 3668, 19975, 24, 31509, 243, ...   \n",
       "382136  blog_9660  [9366, 6, 11954, 6, 132, 12, 19402, 9, 26108, ...   \n",
       "\n",
       "                                             decoded_text  age   topic  gender  \n",
       "0       <s>Even though I am exhausted after today, I m...   25  indUnk  female  \n",
       "1        know it. This hell is otherwise known as U Vi...   25  indUnk  female  \n",
       "2        groom-to-be's scrotal bling, but not the Fout...   25  indUnk  female  \n",
       "3       <s>Hello again.  This is the offical No Action...   26  indUnk    male  \n",
       "4        the singalongs from that, as well as the mino...   26  indUnk    male  \n",
       "...                                                   ...  ...     ...     ...  \n",
       "382132  , but I told her we'd probably better wait on ...   35  indUnk    male  \n",
       "382133  , which is very unfortunate.   I was pretty un...   35  indUnk    male  \n",
       "382134   of the heat strip, disconnected it, and now w...   35  indUnk    male  \n",
       "382135   it with me and absolutely hated it ('It's stu...   35  indUnk    male  \n",
       "382136   pizza, wings, 2-liter of Coke, etc... Pretty ...   35  indUnk    male  \n",
       "\n",
       "[382024 rows x 6 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_blog_data = build_chunk_dataframe(full_blog_corpus, meta_blog_corpus)\n",
    "nunique_blog_data = clean_non_unique(chunked_blog_data)\n",
    "nunique_blog_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "nunique_blog_data.to_csv(\"data/nlp/blog_corpus/blog_as_csv_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mail data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Load data mail_as_csv.csv')\n",
    "mail_corpus = pd.read_csv(\"data/nlp/enron_mail_20150507/mail_as_csv.csv\")\n",
    "mail_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    clean_mail = re.sub(r'(\\\\+r)?(\\\\+n)+', '\\n', text)\n",
    "    clean_mail = re.sub(r'\\\\+t', '\\t', clean_mail)\n",
    "    clean_mail = '\\n'.join(clean_mail.strip().split('\\n')[15:-1])\n",
    "    clean_mail = re.sub(r'X-.+:.*\\n', '<s>', clean_mail)\n",
    "    clean_mail = re.sub(r'From:.*\\n', '', clean_mail)\n",
    "    clean_mail = re.sub(r\"\\\\'\", \"'\", clean_mail)\n",
    "\n",
    "    return clean_mail\n",
    "\n",
    "mail_corpus['clean_text'] = mail_corpus.text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e96f30748cf4e2288502fc92cb341f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (460644 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (454546 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (505057 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691872 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (863829 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (809679 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1077318 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2207991 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2625737 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2445533 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pretokenized_text</th>\n",
       "      <th>decoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mail_101</td>\n",
       "      <td>[0, 28915, 6, 50118, 6715, 3438, 162, 31, 110,...</td>\n",
       "      <td>&lt;s&gt;Brian,\\nPlease remove me from your distribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mail_101</td>\n",
       "      <td>[4, 1437, 22381, 42, 16, 230, 35, 48669, 44426...</td>\n",
       "      <td>.  Usually this is C:\\\\Program Files\\\\Microsof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mail_101</td>\n",
       "      <td>[50118, 39767, 21194, 41552, 37457, 29, 15698,...</td>\n",
       "      <td>\\nGabriel&lt;\\s&gt;Hey do you have to go to the harr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mail_101</td>\n",
       "      <td>[87, 706, 722, 49069, 37457, 29, 15698, 100, 2...</td>\n",
       "      <td>than 24 hours.&lt;\\s&gt;I think harassing me is a v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mail_101</td>\n",
       "      <td>[31271, 4, 50118, 176, 73, 1549, 73, 2663, 143...</td>\n",
       "      <td>520.\\n2/16/01  MANAGEMENT-PWR 177,196.&lt;\\s&gt;I'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63596</th>\n",
       "      <td>mail_19</td>\n",
       "      <td>[246, 495, 5214, 246, 495, 5214, 246, 495, 521...</td>\n",
       "      <td>3D=3D=3D=3D=3D\\nThe object of humor notwithsta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63597</th>\n",
       "      <td>mail_19</td>\n",
       "      <td>[4, 1437, 6830, 5, 414, 6, 79, 64, 75, 224, 93...</td>\n",
       "      <td>.  Without the data, she can't say anything\\nc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63598</th>\n",
       "      <td>mail_19</td>\n",
       "      <td>[50118, 42038, 1258, 4, 1437, 38, 74, 28, 55, ...</td>\n",
       "      <td>\\nparticipation.  I would be more than happy t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63599</th>\n",
       "      <td>mail_19</td>\n",
       "      <td>[0, 0, 0, 0, 0, 50118, 28409, 100, 4, 1437, 45...</td>\n",
       "      <td>&lt;s&gt;&lt;s&gt;&lt;s&gt;&lt;s&gt;&lt;s&gt;\\nFYI.  Thanks to Max at the PX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63600</th>\n",
       "      <td>mail_19</td>\n",
       "      <td>[3170, 4, 612, 1039, 44460, 11762, 38740, 4, 1...</td>\n",
       "      <td>38.00@*.calpx.com&gt;\\nDate: Tue, 22 Aug 2000 11:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>613635 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                  pretokenized_text  \\\n",
       "0      mail_101  [0, 28915, 6, 50118, 6715, 3438, 162, 31, 110,...   \n",
       "1      mail_101  [4, 1437, 22381, 42, 16, 230, 35, 48669, 44426...   \n",
       "2      mail_101  [50118, 39767, 21194, 41552, 37457, 29, 15698,...   \n",
       "3      mail_101  [87, 706, 722, 49069, 37457, 29, 15698, 100, 2...   \n",
       "4      mail_101  [31271, 4, 50118, 176, 73, 1549, 73, 2663, 143...   \n",
       "...         ...                                                ...   \n",
       "63596   mail_19  [246, 495, 5214, 246, 495, 5214, 246, 495, 521...   \n",
       "63597   mail_19  [4, 1437, 6830, 5, 414, 6, 79, 64, 75, 224, 93...   \n",
       "63598   mail_19  [50118, 42038, 1258, 4, 1437, 38, 74, 28, 55, ...   \n",
       "63599   mail_19  [0, 0, 0, 0, 0, 50118, 28409, 100, 4, 1437, 45...   \n",
       "63600   mail_19  [3170, 4, 612, 1039, 44460, 11762, 38740, 4, 1...   \n",
       "\n",
       "                                            decoded_text  \n",
       "0      <s>Brian,\\nPlease remove me from your distribu...  \n",
       "1      .  Usually this is C:\\\\Program Files\\\\Microsof...  \n",
       "2      \\nGabriel<\\s>Hey do you have to go to the harr...  \n",
       "3       than 24 hours.<\\s>I think harassing me is a v...  \n",
       "4      520.\\n2/16/01  MANAGEMENT-PWR 177,196.<\\s>I'm ...  \n",
       "...                                                  ...  \n",
       "63596  3D=3D=3D=3D=3D\\nThe object of humor notwithsta...  \n",
       "63597  .  Without the data, she can't say anything\\nc...  \n",
       "63598  \\nparticipation.  I would be more than happy t...  \n",
       "63599  <s><s><s><s><s>\\nFYI.  Thanks to Max at the PX...  \n",
       "63600  38.00@*.calpx.com>\\nDate: Tue, 22 Aug 2000 11:...  \n",
       "\n",
       "[613635 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mail_corpus.columns = ['user', 'old_text', 'id', 'text']\n",
    "mail_corpus.text = mail_corpus.text.apply(lambda x: x.strip())\n",
    "clean_mail_corpus = mail_corpus[['id', 'text']].groupby(\"id\").agg(lambda x: '<\\s>'.join(x))\n",
    "\n",
    "chunked_mail_data = build_chunk_dataframe(clean_mail_corpus, None)\n",
    "nunique_mail_data = clean_non_unique(chunked_mail_data)\n",
    "nunique_mail_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nunique_mail_data.to_csv(\"data/nlp/enron_mail_20150507/mail_as_csv_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data book_as_csv.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>authoryearofbirth</th>\n",
       "      <th>authoryearofdeath</th>\n",
       "      <th>language</th>\n",
       "      <th>downloads</th>\n",
       "      <th>subjects</th>\n",
       "      <th>id_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n\\nCarmilla\\n\\nby Joseph Sheridan Le Fanu...</td>\n",
       "      <td>PG10007</td>\n",
       "      <td>Carmilla</td>\n",
       "      <td>Le Fanu, Joseph Sheridan</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>3626</td>\n",
       "      <td>{'Vampires -- Fiction', 'Young women -- Fiction'}</td>\n",
       "      <td>book_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n[Illustration]\\n\\n\\n\\n\\nThe Mountains of Cal...</td>\n",
       "      <td>PG10012</td>\n",
       "      <td>The Mountains of California</td>\n",
       "      <td>Muir, John</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>88</td>\n",
       "      <td>{'Natural history -- California', 'Muir, John,...</td>\n",
       "      <td>book_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\nThe Divine Comedy\\n\\nof Dante Alighier...</td>\n",
       "      <td>PG1001</td>\n",
       "      <td>Divine Comedy, Longfellow's Translation, Hell</td>\n",
       "      <td>Dante Alighieri</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>3358</td>\n",
       "      <td>{'Epic poetry, Italian -- Translations into En...</td>\n",
       "      <td>book_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n\\nThe Divine Comedy\\n\\nof Dante Alighier...</td>\n",
       "      <td>PG1002</td>\n",
       "      <td>Divine Comedy, Longfellow's Translation, Purga...</td>\n",
       "      <td>Dante Alighieri</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>57</td>\n",
       "      <td>{'Epic poetry, Italian -- Translations into En...</td>\n",
       "      <td>book_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n\\n\\n                        The Complete P...</td>\n",
       "      <td>PG10031</td>\n",
       "      <td>The Complete Poetical Works of Edgar Allan Poe...</td>\n",
       "      <td>Poe, Edgar Allan</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>1849.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>415</td>\n",
       "      <td>{'Fantasy poetry, American'}</td>\n",
       "      <td>book_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>\\n\\n\\n\\n\\n                             Pastor ...</td>\n",
       "      <td>PG36828</td>\n",
       "      <td>Pastor Pastorum; Or, The Schooling of the Apos...</td>\n",
       "      <td>Latham, Henry</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>33</td>\n",
       "      <td>{'Teaching', 'Jesus Christ'}</td>\n",
       "      <td>book_1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>\\n\\n\\n\\n\\n[Illustration: I summoned â€œLocal Boa...</td>\n",
       "      <td>PG36832</td>\n",
       "      <td>Conscript 2989: Experiences of a Drafted Man</td>\n",
       "      <td>Crump, Irving</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>29</td>\n",
       "      <td>{'Military training camps -- United States', '...</td>\n",
       "      <td>book_1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>\\n\\n\\n\\n\\n[Illustration: GLADYS TURNED THE CAR...</td>\n",
       "      <td>PG36833</td>\n",
       "      <td>The Camp Fire Girls at Onoway House; Or, The M...</td>\n",
       "      <td>Frey, Hildegard G.</td>\n",
       "      <td>1891.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>44</td>\n",
       "      <td>{'Measles -- Juvenile fiction', 'Camp Fire Gir...</td>\n",
       "      <td>book_1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>\\n\\n\\n\\n\\nACRES OF DIAMONDS\\n\\nBy Russell H. C...</td>\n",
       "      <td>PG368</td>\n",
       "      <td>Acres of Diamonds: Our Every-day Opportunities</td>\n",
       "      <td>Conwell, Russell H.</td>\n",
       "      <td>1843.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>303</td>\n",
       "      <td>{'Conwell, Russell H., 1843-1925', 'Success', ...</td>\n",
       "      <td>book_1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>\\n\\n\\n\\nThe Outlaw of Torn\\n\\nby Edgar Rice Bu...</td>\n",
       "      <td>PG369</td>\n",
       "      <td>The Outlaw of Torn</td>\n",
       "      <td>Burroughs, Edgar Rice</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>113</td>\n",
       "      <td>{'Outlaws -- Fiction', 'Great Britain -- Histo...</td>\n",
       "      <td>book_245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2934 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text       id  \\\n",
       "0     \\n\\n\\n\\nCarmilla\\n\\nby Joseph Sheridan Le Fanu...  PG10007   \n",
       "1     \\n[Illustration]\\n\\n\\n\\n\\nThe Mountains of Cal...  PG10012   \n",
       "2     \\n\\n\\n\\nThe Divine Comedy\\n\\nof Dante Alighier...   PG1001   \n",
       "3     \\n\\n\\n\\nThe Divine Comedy\\n\\nof Dante Alighier...   PG1002   \n",
       "4     \\n\\n\\n\\n                        The Complete P...  PG10031   \n",
       "...                                                 ...      ...   \n",
       "2929  \\n\\n\\n\\n\\n                             Pastor ...  PG36828   \n",
       "2930  \\n\\n\\n\\n\\n[Illustration: I summoned â€œLocal Boa...  PG36832   \n",
       "2931  \\n\\n\\n\\n\\n[Illustration: GLADYS TURNED THE CAR...  PG36833   \n",
       "2932  \\n\\n\\n\\n\\nACRES OF DIAMONDS\\n\\nBy Russell H. C...    PG368   \n",
       "2933  \\n\\n\\n\\nThe Outlaw of Torn\\n\\nby Edgar Rice Bu...    PG369   \n",
       "\n",
       "                                                  title  \\\n",
       "0                                              Carmilla   \n",
       "1                           The Mountains of California   \n",
       "2         Divine Comedy, Longfellow's Translation, Hell   \n",
       "3     Divine Comedy, Longfellow's Translation, Purga...   \n",
       "4     The Complete Poetical Works of Edgar Allan Poe...   \n",
       "...                                                 ...   \n",
       "2929  Pastor Pastorum; Or, The Schooling of the Apos...   \n",
       "2930       Conscript 2989: Experiences of a Drafted Man   \n",
       "2931  The Camp Fire Girls at Onoway House; Or, The M...   \n",
       "2932     Acres of Diamonds: Our Every-day Opportunities   \n",
       "2933                                 The Outlaw of Torn   \n",
       "\n",
       "                        author  authoryearofbirth  authoryearofdeath language  \\\n",
       "0     Le Fanu, Joseph Sheridan             1814.0             1873.0   ['en']   \n",
       "1                   Muir, John             1838.0             1914.0   ['en']   \n",
       "2              Dante Alighieri             1265.0             1321.0   ['en']   \n",
       "3              Dante Alighieri             1265.0             1321.0   ['en']   \n",
       "4             Poe, Edgar Allan             1809.0             1849.0   ['en']   \n",
       "...                        ...                ...                ...      ...   \n",
       "2929             Latham, Henry             1821.0             1902.0   ['en']   \n",
       "2930             Crump, Irving             1887.0             1979.0   ['en']   \n",
       "2931        Frey, Hildegard G.             1891.0             1957.0   ['en']   \n",
       "2932       Conwell, Russell H.             1843.0             1925.0   ['en']   \n",
       "2933     Burroughs, Edgar Rice             1875.0             1950.0   ['en']   \n",
       "\n",
       "      downloads                                           subjects       id_2  \n",
       "0          3626  {'Vampires -- Fiction', 'Young women -- Fiction'}     book_0  \n",
       "1            88  {'Natural history -- California', 'Muir, John,...     book_1  \n",
       "2          3358  {'Epic poetry, Italian -- Translations into En...     book_2  \n",
       "3            57  {'Epic poetry, Italian -- Translations into En...     book_2  \n",
       "4           415                       {'Fantasy poetry, American'}     book_3  \n",
       "...         ...                                                ...        ...  \n",
       "2929         33                       {'Teaching', 'Jesus Christ'}  book_1287  \n",
       "2930         29  {'Military training camps -- United States', '...  book_1288  \n",
       "2931         44  {'Measles -- Juvenile fiction', 'Camp Fire Gir...  book_1289  \n",
       "2932        303  {'Conwell, Russell H., 1843-1925', 'Success', ...  book_1290  \n",
       "2933        113  {'Outlaws -- Fiction', 'Great Britain -- Histo...   book_245  \n",
       "\n",
       "[2934 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Load data book_as_csv.csv')\n",
    "book_corpus = pd.read_csv(\"data/nlp/gutenberg/book_as_csv.csv\")\n",
    "book_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    return re.sub(r'\\n\\n+', '\\n', text)[512:]\n",
    "\n",
    "book_corpus['clean_text'] = book_corpus.text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da1d4712d374e88ba23b1446bd224cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2934 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (39958 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (66207 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (63482 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (65489 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (61438 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (113469 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (128749 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (195722 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (284486 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1780828 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pretokenized_text</th>\n",
       "      <th>decoded_text</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>authoryearofbirth</th>\n",
       "      <th>authoryearofdeath</th>\n",
       "      <th>language</th>\n",
       "      <th>downloads</th>\n",
       "      <th>subjects</th>\n",
       "      <th>id_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PG10007</td>\n",
       "      <td>[0, 39986, 10, 2225, 7391, 7, 5, 36455, 3693, ...</td>\n",
       "      <td>&lt;s&gt;Upon a paper attached to the Narrative whic...</td>\n",
       "      <td>Carmilla</td>\n",
       "      <td>Le Fanu, Joseph Sheridan</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>3626</td>\n",
       "      <td>{'Vampires -- Fiction', 'Young women -- Fiction'}</td>\n",
       "      <td>book_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PG10007</td>\n",
       "      <td>[15, 10, 7019, 50118, 20554, 4086, 11, 10, 669...</td>\n",
       "      <td>on a slight\\neminence in a forest. The road, ...</td>\n",
       "      <td>Carmilla</td>\n",
       "      <td>Le Fanu, Joseph Sheridan</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>3626</td>\n",
       "      <td>{'Vampires -- Fiction', 'Young women -- Fiction'}</td>\n",
       "      <td>book_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PG10007</td>\n",
       "      <td>[6, 50118, 8155, 56, 57, 19, 162, 31, 6, 38, 4...</td>\n",
       "      <td>,\\nwho had been with me from, I might almost s...</td>\n",
       "      <td>Carmilla</td>\n",
       "      <td>Le Fanu, Joseph Sheridan</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>3626</td>\n",
       "      <td>{'Vampires -- Fiction', 'Young women -- Fiction'}</td>\n",
       "      <td>book_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PG10007</td>\n",
       "      <td>[802, 2185, 1937, 4, 38, 21, 45, 26851, 6, 13,...</td>\n",
       "      <td>thought myself alone. I was not frightened, f...</td>\n",
       "      <td>Carmilla</td>\n",
       "      <td>Le Fanu, Joseph Sheridan</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>3626</td>\n",
       "      <td>{'Vampires -- Fiction', 'Young women -- Fiction'}</td>\n",
       "      <td>book_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PG10007</td>\n",
       "      <td>[70, 363, 131, 8, 31, 14, 86, 10, 20667, 50118...</td>\n",
       "      <td>all night; and from that time a servant\\nalwa...</td>\n",
       "      <td>Carmilla</td>\n",
       "      <td>Le Fanu, Joseph Sheridan</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>3626</td>\n",
       "      <td>{'Vampires -- Fiction', 'Young women -- Fiction'}</td>\n",
       "      <td>book_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689426</th>\n",
       "      <td>PG36734</td>\n",
       "      <td>[154, 36, 13728, 4, 939, 6, 33906, 4, 28222, 1...</td>\n",
       "      <td>ing (vol. i, pp. 169-70, of the\\n    seventeen...</td>\n",
       "      <td>The Browning CyclopÃ¦dia: A Guide to the Study ...</td>\n",
       "      <td>Berdoe, Edward</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>100</td>\n",
       "      <td>{'Browning, Robert, 1812-1889 -- Encyclopedias'}</td>\n",
       "      <td>book_1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689427</th>\n",
       "      <td>PG36734</td>\n",
       "      <td>[28173, 4, 925, 4, 24030, 2645, 5789, 7, 162, ...</td>\n",
       "      <td>satisfactory. Dr. Garnett writes to me on the...</td>\n",
       "      <td>The Browning CyclopÃ¦dia: A Guide to the Study ...</td>\n",
       "      <td>Berdoe, Edward</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>100</td>\n",
       "      <td>{'Browning, Robert, 1812-1889 -- Encyclopedias'}</td>\n",
       "      <td>book_1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689428</th>\n",
       "      <td>PG36734</td>\n",
       "      <td>[221, 2028, 271, 18, 22, 46354, 46439, 811, 38...</td>\n",
       "      <td>Pindar's \"Fourth Pythian Ode,\" where he speak...</td>\n",
       "      <td>The Browning CyclopÃ¦dia: A Guide to the Study ...</td>\n",
       "      <td>Berdoe, Edward</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>100</td>\n",
       "      <td>{'Browning, Robert, 1812-1889 -- Encyclopedias'}</td>\n",
       "      <td>book_1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689429</th>\n",
       "      <td>PG36734</td>\n",
       "      <td>[11005, 4, 50118, 10975, 401, 742, 20, 1065, 9...</td>\n",
       "      <td>Bible.\\n[6] The above sonnet, by Robert Brown...</td>\n",
       "      <td>The Browning CyclopÃ¦dia: A Guide to the Study ...</td>\n",
       "      <td>Berdoe, Edward</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>100</td>\n",
       "      <td>{'Browning, Robert, 1812-1889 -- Encyclopedias'}</td>\n",
       "      <td>book_1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689430</th>\n",
       "      <td>PG36734</td>\n",
       "      <td>[113, 36, 8596, 23703, 43, 50118, 1437, 22, 10...</td>\n",
       "      <td>\" (page 142)\\n  \"seeks\" corrected to \"seek\" (p...</td>\n",
       "      <td>The Browning CyclopÃ¦dia: A Guide to the Study ...</td>\n",
       "      <td>Berdoe, Edward</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>100</td>\n",
       "      <td>{'Browning, Robert, 1812-1889 -- Encyclopedias'}</td>\n",
       "      <td>book_1281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689430 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                  pretokenized_text  \\\n",
       "0       PG10007  [0, 39986, 10, 2225, 7391, 7, 5, 36455, 3693, ...   \n",
       "1       PG10007  [15, 10, 7019, 50118, 20554, 4086, 11, 10, 669...   \n",
       "2       PG10007  [6, 50118, 8155, 56, 57, 19, 162, 31, 6, 38, 4...   \n",
       "3       PG10007  [802, 2185, 1937, 4, 38, 21, 45, 26851, 6, 13,...   \n",
       "4       PG10007  [70, 363, 131, 8, 31, 14, 86, 10, 20667, 50118...   \n",
       "...         ...                                                ...   \n",
       "689426  PG36734  [154, 36, 13728, 4, 939, 6, 33906, 4, 28222, 1...   \n",
       "689427  PG36734  [28173, 4, 925, 4, 24030, 2645, 5789, 7, 162, ...   \n",
       "689428  PG36734  [221, 2028, 271, 18, 22, 46354, 46439, 811, 38...   \n",
       "689429  PG36734  [11005, 4, 50118, 10975, 401, 742, 20, 1065, 9...   \n",
       "689430  PG36734  [113, 36, 8596, 23703, 43, 50118, 1437, 22, 10...   \n",
       "\n",
       "                                             decoded_text  \\\n",
       "0       <s>Upon a paper attached to the Narrative whic...   \n",
       "1        on a slight\\neminence in a forest. The road, ...   \n",
       "2       ,\\nwho had been with me from, I might almost s...   \n",
       "3        thought myself alone. I was not frightened, f...   \n",
       "4        all night; and from that time a servant\\nalwa...   \n",
       "...                                                   ...   \n",
       "689426  ing (vol. i, pp. 169-70, of the\\n    seventeen...   \n",
       "689427   satisfactory. Dr. Garnett writes to me on the...   \n",
       "689428   Pindar's \"Fourth Pythian Ode,\" where he speak...   \n",
       "689429   Bible.\\n[6] The above sonnet, by Robert Brown...   \n",
       "689430  \" (page 142)\\n  \"seeks\" corrected to \"seek\" (p...   \n",
       "\n",
       "                                                    title  \\\n",
       "0                                                Carmilla   \n",
       "1                                                Carmilla   \n",
       "2                                                Carmilla   \n",
       "3                                                Carmilla   \n",
       "4                                                Carmilla   \n",
       "...                                                   ...   \n",
       "689426  The Browning CyclopÃ¦dia: A Guide to the Study ...   \n",
       "689427  The Browning CyclopÃ¦dia: A Guide to the Study ...   \n",
       "689428  The Browning CyclopÃ¦dia: A Guide to the Study ...   \n",
       "689429  The Browning CyclopÃ¦dia: A Guide to the Study ...   \n",
       "689430  The Browning CyclopÃ¦dia: A Guide to the Study ...   \n",
       "\n",
       "                          author  authoryearofbirth  authoryearofdeath  \\\n",
       "0       Le Fanu, Joseph Sheridan             1814.0             1873.0   \n",
       "1       Le Fanu, Joseph Sheridan             1814.0             1873.0   \n",
       "2       Le Fanu, Joseph Sheridan             1814.0             1873.0   \n",
       "3       Le Fanu, Joseph Sheridan             1814.0             1873.0   \n",
       "4       Le Fanu, Joseph Sheridan             1814.0             1873.0   \n",
       "...                          ...                ...                ...   \n",
       "689426            Berdoe, Edward             1836.0             1916.0   \n",
       "689427            Berdoe, Edward             1836.0             1916.0   \n",
       "689428            Berdoe, Edward             1836.0             1916.0   \n",
       "689429            Berdoe, Edward             1836.0             1916.0   \n",
       "689430            Berdoe, Edward             1836.0             1916.0   \n",
       "\n",
       "       language  downloads                                           subjects  \\\n",
       "0        ['en']       3626  {'Vampires -- Fiction', 'Young women -- Fiction'}   \n",
       "1        ['en']       3626  {'Vampires -- Fiction', 'Young women -- Fiction'}   \n",
       "2        ['en']       3626  {'Vampires -- Fiction', 'Young women -- Fiction'}   \n",
       "3        ['en']       3626  {'Vampires -- Fiction', 'Young women -- Fiction'}   \n",
       "4        ['en']       3626  {'Vampires -- Fiction', 'Young women -- Fiction'}   \n",
       "...         ...        ...                                                ...   \n",
       "689426   ['en']        100   {'Browning, Robert, 1812-1889 -- Encyclopedias'}   \n",
       "689427   ['en']        100   {'Browning, Robert, 1812-1889 -- Encyclopedias'}   \n",
       "689428   ['en']        100   {'Browning, Robert, 1812-1889 -- Encyclopedias'}   \n",
       "689429   ['en']        100   {'Browning, Robert, 1812-1889 -- Encyclopedias'}   \n",
       "689430   ['en']        100   {'Browning, Robert, 1812-1889 -- Encyclopedias'}   \n",
       "\n",
       "             id_2  \n",
       "0          book_0  \n",
       "1          book_0  \n",
       "2          book_0  \n",
       "3          book_0  \n",
       "4          book_0  \n",
       "...           ...  \n",
       "689426  book_1281  \n",
       "689427  book_1281  \n",
       "689428  book_1281  \n",
       "689429  book_1281  \n",
       "689430  book_1281  \n",
       "\n",
       "[689430 rows x 11 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_corpus.columns = ['old_text', 'id', 'title', 'author', 'authoryearofbirth',\n",
    "                        'authoryearofdeath', 'language', 'downloads', 'subjects', 'id_2',\n",
    "                        'text']\n",
    "book_corpus.text = book_corpus.text.apply(lambda x: x.strip())\n",
    "clean_book_corpus = book_corpus[['id', 'text']].groupby(\"id\").agg(lambda x: '<\\s>'.join(x))\n",
    "\n",
    "chunked_book_data = build_chunk_dataframe(clean_book_corpus, book_corpus.drop(['old_text', 'text'], axis=1))\n",
    "nunique_book_data = clean_non_unique(chunked_book_data)\n",
    "nunique_book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'id', 'title', 'author', 'authoryearofbirth',\n",
       "       'authoryearofdeath', 'language', 'downloads', 'subjects', 'id_2',\n",
       "       'clean_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_corpus.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nunique_book_data.to_csv(\"data/nlp/gutenberg/book_as_csv_preprocessed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
